{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Spam email image](https://www.howtogeek.com/wp-content/uploads/2019/04/xemail-bomb.jpg.pagespeed.gp+jp+jw+pj+ws+js+rj+rp+rw+ri+cp+md.ic.UUnEG5yZbp.jpg)\n",
    "# <center><font color = #2E5266>Error Types and Costs: Case Studies</font></center>\n",
    "<center>Statistical models can help us understand and make predictions about the world. But, no model is perfect. Through two real-life case studies of applied machine learning, we will explore how type I and type II errors have consequences for decision-making in different contexts, and how trying to reduce one type can increase another.</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "Before we begin, recall the definitions of the following terms:\n",
    "* <font color = #6E8898>Type I Error</font> is ...\n",
    "* <font color = #6E8898>Type II Error</font> is ...\n",
    "* <font color = #6E8898>Precision</font> is ...\n",
    "* <font color = #6E8898>Recall</font> is ...\n",
    "\n",
    "Now we will explore what is called a <font color = #6E8898>confusion matrix</font>. Now, don't be confused by the confusion matrix. We will explore what exactly it is below.\n",
    "\n",
    "By definition, a confusion matrix $C$ is such that a cell at position $(1,3)$ called $C_{(1,3)}$ is known to be in group 1 and predicted to be in group 3.\n",
    "![](data/matrix_c.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case Study: SMS Spam Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this dataset, we will be studying a collection of SMS messages. Some of these messages are ham (\"real\" messages), and some are spam. To read more about this dataset, please take a look at the `data/readme.txt` file, or visit https://archive.ics.uci.edu/ml/datasets/sms+spam+collection.\n",
    "\n",
    "<font color=#769ECB>// **COMMENTS**: We need to explain the dataset to them. Will update later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'datascience'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-5289eff05b2b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdatascience\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'matplotlib'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'inline'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mipywidgets\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mwidgets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mipywidgets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minteract\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfixed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLayout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'datascience'"
     ]
    }
   ],
   "source": [
    "from datascience import *\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, fixed, Layout\n",
    "import numpy as np\n",
    "import string\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=#769ECB>// **COMMENTS**: We should be including a description for every code cell as they have never programmed before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = Table.read_table(\"data/SMSSpamCollection.csv\")\n",
    "raw_data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split training and testing\n",
    "# 10% data is testing\n",
    "testing = random.sample(range(raw_data.num_rows), raw_data.num_rows//10)\n",
    "\n",
    "# 90% data is training\n",
    "training = [i for i in range(raw_data.num_rows) if i not in testing]\n",
    "\n",
    "testing = raw_data.take[testing]\n",
    "testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'raw_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-c84d8581b4ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtraining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mraw_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'raw_data' is not defined"
     ]
    }
   ],
   "source": [
    "training = raw_data.take[training]\n",
    "training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you read the some of the texts, it is pretty easy to distinguish spam vs ham. However, we are interested in getting a program to tell them apart. \n",
    "\n",
    "Lets try looking at some differences, like the number of capital letters in a text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for generating a histogram! You don't need to know how it works, but feel free to see what each line does\n",
    "def histogram_maker(dataset, seperation_condition, plt, title, std=None, axis=False, show_hist=True):\n",
    "    # gets ham texts from dataset\n",
    "    hams = dataset.where(\"Class\", are.equal_to(\"ham\"))\n",
    "    ham_texts = hams.column(\"Text\")\n",
    "    \n",
    "    # gets spam texts from dataset\n",
    "    spams = dataset.where(\"Class\", are.equal_to(\"spam\"))\n",
    "    spam_texts = spams.column(\"Text\")\n",
    "    \n",
    "    # calculate/collect values (from the seperation_condition) for each ham text\n",
    "    ham_vals = []\n",
    "    for count in range(len(ham_texts)):\n",
    "        ham_vals += [seperation_condition(ham_texts[count])]\n",
    "        \n",
    "    # calculate/collect values (from the seperation_condition) for each spam text\n",
    "    spam_vals = []\n",
    "    for count in range(len(spam_texts)):\n",
    "        spam_vals += [seperation_condition(spam_texts[count])]\n",
    "\n",
    "    # calculate bin range for histogram\n",
    "    all_vals_upper = ham_vals + spam_vals\n",
    "    bins = np.linspace(min(all_vals_upper), np.percentile(all_vals_upper, 99), 40)\n",
    "    \n",
    "    # plot histogram\n",
    "    if show_hist:\n",
    "        if not axis:\n",
    "            plt.figure(num=None, figsize=(7, 4), dpi=80, facecolor='w', edgecolor='k')\n",
    "        plt.hist(ham_vals, alpha=.5, bins=bins, color=\"green\", label=\"ham\", density=True)\n",
    "        plt.hist(spam_vals, alpha=.5, bins=bins, color=\"red\", label=\"spam\", density=True)\n",
    "        if not axis:\n",
    "            plt.xlabel(title)\n",
    "            plt.ylabel(\"Frequency\")\n",
    "        else:\n",
    "            plt.set_xlabel(title)\n",
    "            plt.set_ylabel(\"Frequency\")\n",
    "        plt.legend()\n",
    "    \n",
    "    # calculate and return the calculated values for ham and spam DIVIDED BY the standard deviation. This is to equally \n",
    "    # weigh each statistic when making the k-nearest neighbors plot \n",
    "    if std is None:\n",
    "        stdev = np.std(all_vals_upper)\n",
    "    else: \n",
    "        stdev = std\n",
    "    ham_vals = [i/stdev for i in ham_vals]\n",
    "    spam_vals = [i/stdev for i in spam_vals]\n",
    "\n",
    "    return (ham_vals, spam_vals, stdev)\n",
    "\n",
    "# define a function that returns the number of Upper case letters given a text\n",
    "number_of_uppers_f = (lambda text : (len([i for i in text if i.isupper()])))\n",
    "# generate histogram\n",
    "ham_vals_number_uppers, spam_vals_number_uppers, std_number_uppers = histogram_maker(training, number_of_uppers_f, plt, \"Number of Uppers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the histogram above, there is a statistical difference in the number of uppercase letters between spam and ham text messsages. However, this could be because perhaps spam messages are longer in general, and so have a higher number of upper case letters as a result. Next, lets try looking at the ratio of uppercase letters within a message (ie number of uppercase letters divided by the number of characters in a text):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function that returns the ratio of Upper case letters given a text\n",
    "ratio_of_uppers_f = (lambda j : (len([i for i in j if i.isupper()])/len(j)))\n",
    "# generate histogram\n",
    "ham_vals_ratio_uppers, spam_vals_ratio_uppers, std_ratio_uppers = histogram_maker(training, ratio_of_uppers_f, plt, \"Ratio of Uppers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, it does indeed bring the spam distribution closer to the ham histogram. However, there still is a noticable shift in peaks between spam and ham messages.\n",
    "\n",
    "This is one of many aspects that can differentiate spam vs ham messages. Discuss other features we can use to distinguish spam vs ham message in the box below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Double-click here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How about we choose a specific group of characters to classify these messages; say we have certain \"target characters,\" and we count the number of instances those characters are in the messages. We can expect a distinction between spam and ham messages, assuming we chose the right characters. We will be having you choosing some distinct characters to classify these messages. Here are some helpful guidelines in choosing these characters to make the best classifier:\n",
    "\n",
    "    - DO NOT chose half of the characters that are common among one group, then the other half among the other. Eg, do not choose 3 characters that are associated with ham messages, then 3 characters that are associated with spam messages. These characters are to be weighted EQUALY, and so getting a number like 3 could mean a message is either spam or ham. Try to find characters that are all associated with ham messages, or characters that are associated with spam messages.\n",
    "    \n",
    "    - Try experiementing with the number of characters to choose, and which characters to choose!\n",
    "    \n",
    "    - Consider maybe looking at punctuation, numbers, or even symbols.\n",
    "    \n",
    "    - Need help thinking of words? Try going to the data folder and opening SMSSpamCollection.txt to read some spam/ham messages for inspiration!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# targets = []\n",
    "# example targets list should look something like [\"a\", \"B\", \"&\", \"7\"]\n",
    "targets = [\"?\", \"!\", \"*\"] + [i for i in string.ascii_uppercase] + [str(i) for i in range(0, 10)]\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function that returns the number of target characters given a text\n",
    "num_of_targets_f = (lambda j : (len([i for i in j if i in targets])))\n",
    "# generate histogram\n",
    "ham_vals_num_targets, spam_vals_num_targets, std_num_targets = histogram_maker(training, num_of_targets_f, plt, \"Number of targets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function that returns the ratio of target characters given a text\n",
    "ratio_of_targets_f = (lambda j : (len([i for i in j if i in targets])/len(j)))\n",
    "# generate histogram\n",
    "ham_vals_ratio_targets, spam_vals_ratio_targets, std_ratio_targets = histogram_maker(training, ratio_of_targets_f, plt, \"Ratio of targets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's look more general characteristics of the messages. For example, let's check out the distribution of the number of words and characters in a message:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function that returns the number of words given a text\n",
    "num_words_f = (lambda j : (len([i for i in j.split(\" \")])))\n",
    "# generate histogram\n",
    "ham_vals_num_words, spam_vals_num_words, std_num_words = histogram_maker(training, num_words_f, plt, \"Number of words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function that returns the number of characters given a text\n",
    "num_chara_f = (lambda j : (len(j)))\n",
    "# generate histogram\n",
    "ham_vals_num_chara, spam_vals_num_chara, std_num_chara = histogram_maker(training, num_chara_f, plt, \"Number of characters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we combine both of these statistics, we can find the average characters per word attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function that returns the average number of characters per word given a text\n",
    "avg_len_word_f = (lambda j : (len([i for i in j if i is not \" \"]))/(len([i for i in j.split(\" \")])))\n",
    "# generate histogram\n",
    "ham_vals_avg_len_word, spam_vals_avg_len_word, std_avg_len_word = histogram_maker(training, avg_len_word_f, plt, \"Average number of characters per word\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, if we plot one one attribute vs another, cluster the spam messages against the ham messages. Try plying around with the widget below to see which combination of attributes best differnetiate the spam messages vs the ham messages!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seps = [[('Number of Uppers', 0), ham_vals_number_uppers, spam_vals_number_uppers, std_number_uppers, number_of_uppers_f], \n",
    "        [('Ratio of Uppers', 1), ham_vals_ratio_uppers, spam_vals_ratio_uppers, std_ratio_uppers, ratio_of_uppers_f], \n",
    "        [('Number of Targets', 2), ham_vals_num_targets, spam_vals_num_targets, std_num_targets, num_of_targets_f],\n",
    "        [('Ratio of Targets', 3), ham_vals_ratio_targets, spam_vals_ratio_targets, std_ratio_targets, ratio_of_targets_f], \n",
    "        [('Number of Words', 4), ham_vals_num_words, spam_vals_num_words, std_num_words, num_words_f], \n",
    "        [('Number of Characters', 5), ham_vals_num_chara, spam_vals_num_chara, std_num_chara, num_chara_f],\n",
    "        [('Average len of words', 6), ham_vals_avg_len_word, spam_vals_avg_len_word, std_avg_len_word, avg_len_word_f],]\n",
    "\n",
    "def plot_scatter(x, y):\n",
    "    ham_x = seps[x][1]\n",
    "    spam_x = seps[x][2]\n",
    "    \n",
    "    ham_y = seps[y][1]\n",
    "    spam_y = seps[y][2]\n",
    "    plt.figure(num=None, figsize=(11, 11), dpi=80, facecolor='w', edgecolor='k')\n",
    "    \n",
    "    ax3 = plt.subplot2grid((3, 3), (1, 0), colspan=2, rowspan=2)\n",
    "    ax2 = plt.subplot2grid((3, 3), (1, 2), rowspan=1)\n",
    "    ax1 = plt.subplot2grid((3, 3), (2, 2), rowspan=1)\n",
    "    \n",
    "    histogram_maker(training, seps[x][4], ax1, seps[x][0][0], axis=True)\n",
    "    histogram_maker(training, seps[y][4], ax2, seps[y][0][0], axis=True)\n",
    "    \n",
    "    ax3.scatter(ham_x, ham_y, color=\"green\", alpha=0.4, label=\"ham message\")\n",
    "    ax3.scatter(spam_x, spam_y, color=\"red\", alpha=0.4, label=\"spam message\")\n",
    "\n",
    "    ax3.scatter([np.mean(ham_x)], [np.mean(ham_y)], marker=\"*\", s=400, color=\"green\", edgecolors=\"black\", linewidths=2, label=\"centroid of ham\")\n",
    "    ax3.scatter([np.mean(spam_x)], [np.mean(spam_y)], marker=\"*\", s=400, color=\"red\", edgecolors=\"black\", linewidths=2, label=\"centroid of spam\")\n",
    "    \n",
    "    ax3.set_xlabel(seps[x][0][0] + \" (Normalized)\")\n",
    "    ax3.set_ylabel(seps[y][0][0] + \" (Normalized)\")\n",
    "    ax3.legend()\n",
    "    \n",
    "    ax3.axis([np.min(ham_x+spam_x), np.percentile(ham_x+spam_x, 99.9), np.min(ham_y+spam_y), np.percentile(ham_y+spam_y, 99.9)])\n",
    "    plt.tight_layout()\n",
    "\n",
    "interact(plot_scatter, x=[i[0] for i in seps], y=[i[0] for i in seps]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__EXPLAIN K NEAREST NEIGHBORS__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-Nearest Neighbors takes attributes (called features) from a dataset and identifies each attribute as one of two categories (called labels). It selects lables according to previously seen examples. In the spam dataset, the labels are \"spam\" and \"ham.\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes = [3, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_nearest_neighbors(testing, seps, attribute1, attribute2, k):\n",
    "    attributes = [attribute1, attribute2]\n",
    "    total_x = seps[attribute1][1]+seps[attribute1][2]\n",
    "    total_y = seps[attribute2][1]+seps[attribute2][2]\n",
    "    ham_length=len(seps[attributes[0]][1])\n",
    "\n",
    "    all_points = []\n",
    "    for i in range(len(total_x)):\n",
    "        if i < ham_length:\n",
    "            all_points += [[total_x[i], total_y[i], True]]\n",
    "        else:\n",
    "            all_points += [[total_x[i], total_y[i], False]]\n",
    "            \n",
    "    texts = testing.column(\"Text\")\n",
    "    ham_vals_x, spam_vals_x = histogram_maker(testing, seps[attribute1][4], plt, \" \", \n",
    "                                              show_hist=False, std=seps[attribute1][3])[0:2]\n",
    "    ham_vals_y, spam_vals_y = histogram_maker(testing, seps[attributes[1]][4], plt, \" \", \n",
    "                                              show_hist=False, std=seps[attribute2][3])[0:2]\n",
    "    \n",
    "    test_points_ham = [[ham_vals_x[i], ham_vals_y[i], True] for i in range(0, len(ham_vals_x))]\n",
    "    test_points_spam = [[spam_vals_x[i], spam_vals_y[i], False] for i in range(0, len(spam_vals_x))]\n",
    "    test_points = test_points_ham + test_points_spam\n",
    "    \n",
    "    cor_ham = 0\n",
    "    cor_spam = 0\n",
    "    mislabel_as_ham = 0\n",
    "    mislabel_as_spam = 0\n",
    "    for point in test_points:\n",
    "        def distance(x, y):\n",
    "           return ((x-point[0])**2 + (y-point[1])**2)**0.5\n",
    "        distance_distinction = [[distance(x, y), z] for x,y,z in all_points]\n",
    "        distance_distinction.sort()\n",
    "        top = distance_distinction[0:k]\n",
    "        hams = np.sum([i[1] for i in top])\n",
    "        if (hams >= k//2+1) and (point[2]):\n",
    "            cor_ham+=1\n",
    "        elif (hams >= k//2+1) and not (point[2]):\n",
    "            mislabel_as_ham+=1\n",
    "        elif (hams < k//2+1) and not (point[2]):\n",
    "            cor_spam+=1\n",
    "        elif (hams < k//2+1) and (point[2]):\n",
    "            mislabel_as_spam+=1\n",
    "\n",
    "    precision = (cor_ham)/(cor_ham+mislabel_as_ham)\n",
    "    recall = (cor_ham)/(cor_ham+mislabel_as_spam)\n",
    "    accuracy = (cor_ham+cor_spam)/(cor_ham+cor_spam+mislabel_as_ham+mislabel_as_spam)\n",
    "\n",
    "    print(\"k: {}\".format(k))\n",
    "    print(\"1st attribute: {}\".format(seps[attribute1][0][0]))\n",
    "    print(\"2nd attribute: {}\".format(seps[attribute2][0][0]))\n",
    "    print(\"precision: {}\".format(precision))\n",
    "    print(\"recall: {}\".format(recall))\n",
    "    print(\"accuracy: {}\".format(accuracy))\n",
    "\n",
    "    t = Table()\n",
    "    return t.with_columns(\" \", [\"actual ham\", \"actual spam\"], \"predicted ham\", [cor_ham, mislabel_as_ham], \n",
    "                          \"predicted spam\", [mislabel_as_spam, cor_spam])\n",
    "\n",
    "k_nearest_neighbors(testing, seps, attributes[0], attributes[1], 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interact(k_nearest_neighbors, testing=fixed(testing), seps=fixed(seps), attribute1=[i[0] for i in seps], \n",
    "         attribute2=[i[0] for i in seps], k=widgets.IntSlider(min=1, max=1259, step=2, value=3, \n",
    "                                                              layout=Layout(width='80%')));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
